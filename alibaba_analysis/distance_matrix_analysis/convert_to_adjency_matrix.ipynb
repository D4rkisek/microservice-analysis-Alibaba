{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from raphtory import Graph\n",
    "\n",
    "def load_graphs_lazy(graph_paths):\n",
    "    \"\"\"Generator function to lazily load graphs from files.\"\"\"\n",
    "    for path in graph_paths:\n",
    "        if os.path.isfile(path):\n",
    "            print(f\"Loading graph from: {path}\")\n",
    "            yield Graph.load_from_file(path)\n",
    "        else:\n",
    "            print(f\"File does not exist: {path}\")\n",
    "            yield None\n",
    "\n",
    "graph_paths = [f\"C:/ms_bincode/Graph_{i}\" for i in range(1, 25)]\n",
    "\n",
    "# Use the generator to iterate over graphs lazily\n",
    "graphs_lazy = load_graphs_lazy(graph_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raphtory import Graph\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "Convertion of multiple graph binecode files into adjacency matrices\n",
    "\"\"\"\n",
    "\n",
    "def load_graphs_lazy(graph_paths):\n",
    "    \"\"\"Generator function to lazily load graphs from files.\"\"\"\n",
    "    for path in graph_paths:\n",
    "        if os.path.isfile(path):\n",
    "            print(f\"Loading graph from: {path}\")\n",
    "            yield Graph.load_from_file(path)\n",
    "        else:\n",
    "            print(f\"File does not exist: {path}\")\n",
    "            yield None\n",
    "\n",
    "def transfor_into_adjacency_matrix(graph):\n",
    "    node_index = {node_name: i for i, node_name in enumerate(list(graph.vertices.name))}\n",
    "    adjacency_matrix = np.zeros((len(node_index), len(node_index)), dtype=int)\n",
    "    for edge in graph.edges:\n",
    "        src_index = node_index[edge.src.name]\n",
    "        dst_index = node_index[edge.dst.name]\n",
    "        adjacency_matrix[src_index, dst_index] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "graph_paths = [f\"C:/ms_bincode/Graph_{i}\" for i in range(4, 5)]\n",
    "\n",
    "# Use the generator to iterate over graphs lazily\n",
    "graphs_lazy = load_graphs_lazy(graph_paths)\n",
    "\n",
    "# Initialise a nested dictionary\n",
    "A_dict = {}\n",
    "\n",
    "# Use the generator to iterate over graphs lazily\n",
    "for i, graph in enumerate(graphs_lazy):\n",
    "    if graph is not None:\n",
    "        # For each minute segment, generate an adjacency matrix and store it.\n",
    "        A_dict[f\"g{i+1}\"] = {}\n",
    "        for windowed_graph in graph.rolling(window=60000):\n",
    "            minute_graph_segment = windowed_graph\n",
    "            adjacency_matrix = transfor_into_adjacency_matrix(minute_graph_segment)\n",
    "            A_dict[f\"g{i+1}\"][str(windowed_graph)] = adjacency_matrix\n",
    "\n",
    "\n",
    "# Pickle the nested dictionary\n",
    "with open(\"graphs_adjacency_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(A_dict, f)\n",
    "\n",
    "print(\"Nested dictionary pickled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion of a single graph binecode file into an adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(number_of_edges=91201, number_of_vertices=25666, number_of_temporal_edges=145486068, earliest_time=\"10800000\", latest_time=\"14399999\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from raphtory import Graph\n",
    "\n",
    "# Specify the file path\n",
    "binecode_path = \"C:/ms_bincode/Graph_4\"\n",
    "\n",
    "# Load the file\n",
    "if os.path.isfile(binecode_path):\n",
    "    g = Graph.load_from_file(binecode_path)\n",
    "    print(g)\n",
    "else:\n",
    "    print(f\"File does not exist: {binecode_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "def populate_adjacency_matrix(graph, adjacency_matrix):\n",
    "    node_index = {node_name: i for i, node_name in enumerate(list(graph.vertices.name))}\n",
    "    for edge in graph.edges:\n",
    "        adjacency_matrix[node_index[edge.src.name], node_index[edge.dst.name]] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "# Initialise a nested dictionary\n",
    "A_dict = {}\n",
    "segment_counter = 1\n",
    "\n",
    "# Instead of a dense matrix, initialise a sparse adjacency matrix using LIL format for efficient insertion\n",
    "num_vertices = len(list(g.vertices.name))\n",
    "adjacency_matrix = lil_matrix((num_vertices, num_vertices), dtype=int)\n",
    "\n",
    "# For each minute segment, generate an adjacency matrix and store it as a CSR matrix for efficient arithmetic and matrix operations later\n",
    "for windowed_graph in g.rolling(window=60000):\n",
    "    # Make sure to create a new sparse matrix for each window to avoid overwriting\n",
    "    populated_adjacency_matrix = populate_adjacency_matrix(windowed_graph, adjacency_matrix.copy())\n",
    "    # Convert to CSR format after populating for efficient storage and future operations\n",
    "    A_dict[str(segment_counter)] = populated_adjacency_matrix.tocsr()\n",
    "    segment_counter += 1  # Increment the segment counter for the next segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 23296 stored elements in Compressed Sparse Row format>, '2': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22678 stored elements in Compressed Sparse Row format>, '3': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22088 stored elements in Compressed Sparse Row format>, '4': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22255 stored elements in Compressed Sparse Row format>, '5': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22492 stored elements in Compressed Sparse Row format>, '6': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22506 stored elements in Compressed Sparse Row format>, '7': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22171 stored elements in Compressed Sparse Row format>, '8': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21981 stored elements in Compressed Sparse Row format>, '9': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21631 stored elements in Compressed Sparse Row format>, '10': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21479 stored elements in Compressed Sparse Row format>, '11': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22037 stored elements in Compressed Sparse Row format>, '12': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21708 stored elements in Compressed Sparse Row format>, '13': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21425 stored elements in Compressed Sparse Row format>, '14': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21771 stored elements in Compressed Sparse Row format>, '15': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21526 stored elements in Compressed Sparse Row format>, '16': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21962 stored elements in Compressed Sparse Row format>, '17': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21574 stored elements in Compressed Sparse Row format>, '18': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21240 stored elements in Compressed Sparse Row format>, '19': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21564 stored elements in Compressed Sparse Row format>, '20': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21653 stored elements in Compressed Sparse Row format>, '21': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22479 stored elements in Compressed Sparse Row format>, '22': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21408 stored elements in Compressed Sparse Row format>, '23': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21948 stored elements in Compressed Sparse Row format>, '24': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21947 stored elements in Compressed Sparse Row format>, '25': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21772 stored elements in Compressed Sparse Row format>, '26': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21824 stored elements in Compressed Sparse Row format>, '27': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21718 stored elements in Compressed Sparse Row format>, '28': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21202 stored elements in Compressed Sparse Row format>, '29': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21710 stored elements in Compressed Sparse Row format>, '30': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21892 stored elements in Compressed Sparse Row format>, '31': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 23366 stored elements in Compressed Sparse Row format>, '32': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22530 stored elements in Compressed Sparse Row format>, '33': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22609 stored elements in Compressed Sparse Row format>, '34': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22605 stored elements in Compressed Sparse Row format>, '35': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22425 stored elements in Compressed Sparse Row format>, '36': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 22510 stored elements in Compressed Sparse Row format>, '37': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 23384 stored elements in Compressed Sparse Row format>, '38': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 23592 stored elements in Compressed Sparse Row format>, '39': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 23524 stored elements in Compressed Sparse Row format>, '40': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 23800 stored elements in Compressed Sparse Row format>, '41': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 24565 stored elements in Compressed Sparse Row format>, '42': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 24919 stored elements in Compressed Sparse Row format>, '43': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 25098 stored elements in Compressed Sparse Row format>, '44': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 25088 stored elements in Compressed Sparse Row format>, '45': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 25711 stored elements in Compressed Sparse Row format>, '46': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 26656 stored elements in Compressed Sparse Row format>, '47': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 27569 stored elements in Compressed Sparse Row format>, '48': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 28732 stored elements in Compressed Sparse Row format>, '49': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 30279 stored elements in Compressed Sparse Row format>, '50': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 30722 stored elements in Compressed Sparse Row format>, '51': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 32285 stored elements in Compressed Sparse Row format>, '52': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 32297 stored elements in Compressed Sparse Row format>, '53': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 32382 stored elements in Compressed Sparse Row format>, '54': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 32613 stored elements in Compressed Sparse Row format>, '55': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 32055 stored elements in Compressed Sparse Row format>, '56': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 31819 stored elements in Compressed Sparse Row format>, '57': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 29681 stored elements in Compressed Sparse Row format>, '58': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 27859 stored elements in Compressed Sparse Row format>, '59': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 25358 stored elements in Compressed Sparse Row format>, '60': <25666x25666 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 21675 stored elements in Compressed Sparse Row format>}\n"
     ]
    }
   ],
   "source": [
    "print(A_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy.sparse.linalg import eigsh  # For computing eigenvalues of sparse matrices\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def eigenspectrum_sparse(L, k=6):\n",
    "    # Compute the k smallest eigenvalues using shift-invert mode for better precision on small eigenvalues\n",
    "    # Adjust k based on the number of eigenvalues you're interested in\n",
    "    eigvals, _ = eigsh(L, k=k, which='SM', return_eigenvectors=False)\n",
    "    return eigvals\n",
    "\n",
    "def compute_eigenspectrum(args):\n",
    "    A, norm = args\n",
    "    L = laplacian(A, normed=norm, return_diag=False)\n",
    "    return eigenspectrum_sparse(L)\n",
    "\n",
    "def all_spectrums_sparse_parallel(A_dict, norm=True, num_processes=None):\n",
    "    num_graphs = len(A_dict)\n",
    "    num_nodes = next(iter(A_dict.values())).shape[0]\n",
    "    # Assuming we are interested in a smaller subset of eigenvalues for such large matrices\n",
    "    k = min(6, num_nodes-1)  # Adjust based on your specific needs\n",
    "    eigenspectrums_transposed = np.zeros((num_graphs, k))\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "        results = list(executor.map(compute_eigenspectrum, [(A_dict[key], norm) for key in A_dict]))\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        eigenspectrums_transposed[i, :] = result\n",
    "\n",
    "    return eigenspectrums_transposed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenspectrums = all_spectrums_parallel(A_dict, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the result\n",
    "print(eigenspectrums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystates import all_spectrums, snapshot_dist\n",
    "from scipy.spatial import distance\n",
    "import pickle\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "dist2 = distance.cdist(eigenspectrums,eigenspectrums,'euclidean')\n",
    "mds = MDS(n_components=3,dissimilarity='precomputed',random_state=0)\n",
    "results = mds.fit(dist1)\n",
    "coords = results.embedding_\n",
    "\n",
    "agg = AgglomerativeClustering().fit(coords)\n",
    "labels = agg.labels_\n",
    "colours = []\n",
    "for i in range(np.max(labels)+1):\n",
    "    colours.append('#%06X' % randint(0, 0xFFFFFF))\n",
    "cmap=[]\n",
    "for i in labels:\n",
    "    cmap.append(colours[i])\n",
    "plt.figure()\n",
    "plt.scatter(coords[:,0],coords[:,1],c=cmap)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(labels,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "def eigenspectrum(L):\n",
    "    # Calculate the eigenvalues, take their real part, sort in ascending order\n",
    "    eigvals = np.linalg.eigvalsh(L)  # eigvalsh is more efficient for Hermitian matrices\n",
    "    return np.sort(eigvals)\n",
    "\n",
    "    \n",
    "def all_spectrums(A_dict, eigenspectrums_transposed, norm=True):\n",
    "    # Process each adjacency matrix\n",
    "    for i, (key, A) in enumerate(A_dict.items()):\n",
    "        L = laplacian(A, normed=norm)\n",
    "        eigenspectrums_transposed[i, :] = eigenspectrum(L)\n",
    "\n",
    "    # No need to transpose at the end, as we fill the array in the desired orientation\n",
    "    return eigenspectrums_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.zeros((len(list(g.vertices.name)), len(list(g.vertices.name))), dtype=int)\n",
    "eigenspectrums = all_spectrums(A_dict,norm=True, adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Identify all unique nodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print(list(g.vertices.name))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# [ms3123,ms323,...]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a node index map\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m node_index \u001b[38;5;241m=\u001b[39m {node_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, node_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mg\u001b[49m\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mname))}\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(node_index)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# [ms3123:0, ms323:1,...]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialise adjacency matrix\u001b[39;00m\n\u001b[0;32m     14\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(g\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mname)), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(g\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mname))), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "from raphtory import Graph\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Incoporate lazy loading\n",
    "\n",
    "# Identify all unique nodes\n",
    "#print(list(g.vertices.name))\n",
    "# [ms3123,ms323,...]\n",
    "\n",
    "# Create a node index map\n",
    "node_index = {node_name: i for i, node_name in enumerate(list(g.vertices.name))}\n",
    "#print(node_index)\n",
    "# [ms3123:0, ms323:1,...]\n",
    "\n",
    "# Initialise adjacency matrix\n",
    "adjacency_matrix = np.zeros((len(list(g.vertices.name)), len(list(g.vertices.name))), dtype=int)\n",
    "\n",
    "# Populate adjacency matrix\n",
    "for edge in g.edges:\n",
    "    src_index = node_index[edge.src.name]\n",
    "    dst_index = node_index[edge.dst.name]\n",
    "\n",
    "    adjacency_matrix[src_index, dst_index] = 1\n",
    "\n",
    "#print(adjacency_matrix)\n",
    "#[[0 1 0 ... 0 0 0]\n",
    "# [0 0 0 ... 0 0 0]\n",
    "# [0 0 1 ... 0 0 0]\n",
    "# ...\n",
    "# [0 0 0 ... 0 0 0]\n",
    "# [0 0 0 ... 0 0 0]\n",
    "# [0 0 0 ... 0 0 0]]\n",
    "\n",
    "A_dict = {'1': adjacency_matrix}\n",
    "print(A_dict)\n",
    "\n",
    "# Turn in into a nested dictionaries\n",
    "\n",
    "# Such as:\n",
    "# A_dict = {\n",
    "#  \"g1\" : {\n",
    "#       \"1\" : adjacency_matrix,\n",
    "#       \"2\" : adjacency_matrix,\n",
    "#           .\n",
    "#           .\n",
    "#           .\n",
    "#   },\n",
    "#   \"g2\" : {\n",
    "#       \"1\" : adjacency_matrix,\n",
    "#       \"2\" : adjacency_matrix,\n",
    "#           .\n",
    "#           .\n",
    "#           .\n",
    "#   },\n",
    "#}\n",
    "\n",
    "# Pickle the dictionary variable\n",
    "with open(\"graphs_adjacency_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(A_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
