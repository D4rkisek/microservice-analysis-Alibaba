{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from raphtory import Graph\n",
    "\n",
    "def load_graphs_lazy(graph_paths):\n",
    "    \"\"\"Generator function to lazily load graphs from files.\"\"\"\n",
    "    for path in graph_paths:\n",
    "        if os.path.isfile(path):\n",
    "            print(f\"Loading graph from: {path}\")\n",
    "            yield Graph.load_from_file(path)\n",
    "        else:\n",
    "            print(f\"File does not exist: {path}\")\n",
    "            yield None\n",
    "\n",
    "graph_paths = [f\"C:/ms_bincode/Graph_{i}\" for i in range(1, 25)]\n",
    "\n",
    "# Use the generator to iterate over graphs lazily\n",
    "graphs_lazy = load_graphs_lazy(graph_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raphtory import Graph\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "Convertion of multiple graph binecode files into adjacency matrices\n",
    "\"\"\"\n",
    "\n",
    "def load_graphs_lazy(graph_paths):\n",
    "    \"\"\"Generator function to lazily load graphs from files.\"\"\"\n",
    "    for path in graph_paths:\n",
    "        if os.path.isfile(path):\n",
    "            print(f\"Loading graph from: {path}\")\n",
    "            yield Graph.load_from_file(path)\n",
    "        else:\n",
    "            print(f\"File does not exist: {path}\")\n",
    "            yield None\n",
    "\n",
    "def transfor_into_adjacency_matrix(graph):\n",
    "    node_index = {node_name: i for i, node_name in enumerate(list(graph.vertices.name))}\n",
    "    adjacency_matrix = np.zeros((len(node_index), len(node_index)), dtype=int)\n",
    "    for edge in graph.edges:\n",
    "        src_index = node_index[edge.src.name]\n",
    "        dst_index = node_index[edge.dst.name]\n",
    "        adjacency_matrix[src_index, dst_index] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "graph_paths = [f\"C:/ms_bincode/Graph_{i}\" for i in range(4, 5)]\n",
    "\n",
    "# Use the generator to iterate over graphs lazily\n",
    "graphs_lazy = load_graphs_lazy(graph_paths)\n",
    "\n",
    "# Initialise a nested dictionary\n",
    "A_dict = {}\n",
    "\n",
    "# Use the generator to iterate over graphs lazily\n",
    "for i, graph in enumerate(graphs_lazy):\n",
    "    if graph is not None:\n",
    "        # Implement a logic to divide the graph into one-minute segments.\n",
    "        # For each minute segment, generate an adjacency matrix and store it.\n",
    "        A_dict[f\"g{i+1}\"] = {}\n",
    "        for windowed_graph in graph.rolling(window=60000):\n",
    "            # Replace the following line with actual logic to get the specific minute's graph segment\n",
    "            minute_graph_segment = windowed_graph  # Placeholder for actual segmentation logic\n",
    "            adjacency_matrix = transfor_into_adjacency_matrix(minute_graph_segment)\n",
    "            A_dict[f\"g{i+1}\"][str(windowed_graph)] = adjacency_matrix\n",
    "\n",
    "\n",
    "# Pickle the nested dictionary\n",
    "with open(\"graphs_adjacency_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(A_dict, f)\n",
    "\n",
    "print(\"Nested dictionary pickled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raphtory import Graph\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\"\"\"\n",
    "Convertion of a single graph binecode file into an adjacency matrix\n",
    "\"\"\"\n",
    "\n",
    "def transfor_into_adjacency_matrix(graph):\n",
    "    node_index = {node_name: i for i, node_name in enumerate(list(graph.vertices.name))}\n",
    "    adjacency_matrix = np.zeros((len(node_index), len(node_index)), dtype=int)\n",
    "    for edge in graph.edges:\n",
    "        src_index = node_index[edge.src.name]\n",
    "        dst_index = node_index[edge.dst.name]\n",
    "        adjacency_matrix[src_index, dst_index] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "# Specify the file path\n",
    "binecode_path = \"D:/Graph_4\"\n",
    "\n",
    "# Load the file\n",
    "if os.path.isfile(binecode_path):\n",
    "    g = Graph.load_from_file(binecode_path)\n",
    "    print(g)\n",
    "else:\n",
    "    print(f\"File does not exist: {binecode_path}\")\n",
    "\n",
    "# Initialise a nested dictionary\n",
    "A_dict = {}\n",
    "\n",
    "# For each minute segment, generate an adjacency matrix and store it.\n",
    "A_dict[\"g\"] = {}\n",
    "for windowed_graph in g.rolling(window=60000):\n",
    "    # Replace the following line with actual logic to get the specific minute's graph segment\n",
    "    minute_graph_segment = windowed_graph  # Placeholder for actual segmentation logic\n",
    "    adjacency_matrix = transfor_into_adjacency_matrix(minute_graph_segment)\n",
    "    A_dict[\"g\"][str(windowed_graph)] = adjacency_matrix\n",
    "\n",
    "\n",
    "# Pickle the nested dictionary\n",
    "with open(\"graphs_adjacency_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(A_dict, f)\n",
    "\n",
    "print(\"Nested dictionary pickled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Identify all unique nodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print(list(g.vertices.name))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# [ms3123,ms323,...]\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a node index map\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m node_index \u001b[38;5;241m=\u001b[39m {node_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, node_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mg\u001b[49m\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mname))}\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(node_index)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# [ms3123:0, ms323:1,...]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialise adjacency matrix\u001b[39;00m\n\u001b[0;32m     14\u001b[0m adjacency_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(g\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mname)), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(g\u001b[38;5;241m.\u001b[39mvertices\u001b[38;5;241m.\u001b[39mname))), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "from raphtory import Graph\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Incoporate lazy loading\n",
    "\n",
    "# Identify all unique nodes\n",
    "#print(list(g.vertices.name))\n",
    "# [ms3123,ms323,...]\n",
    "\n",
    "# Create a node index map\n",
    "node_index = {node_name: i for i, node_name in enumerate(list(g.vertices.name))}\n",
    "#print(node_index)\n",
    "# [ms3123:0, ms323:1,...]\n",
    "\n",
    "# Initialise adjacency matrix\n",
    "adjacency_matrix = np.zeros((len(list(g.vertices.name)), len(list(g.vertices.name))), dtype=int)\n",
    "\n",
    "# Populate adjacency matrix\n",
    "for edge in g.edges:\n",
    "    src_index = node_index[edge.src.name]\n",
    "    dst_index = node_index[edge.dst.name]\n",
    "\n",
    "    adjacency_matrix[src_index, dst_index] = 1\n",
    "\n",
    "#print(adjacency_matrix)\n",
    "#[[0 1 0 ... 0 0 0]\n",
    "# [0 0 0 ... 0 0 0]\n",
    "# [0 0 1 ... 0 0 0]\n",
    "# ...\n",
    "# [0 0 0 ... 0 0 0]\n",
    "# [0 0 0 ... 0 0 0]\n",
    "# [0 0 0 ... 0 0 0]]\n",
    "\n",
    "A_dict = {'1': adjacency_matrix}\n",
    "print(A_dict)\n",
    "\n",
    "# Turn in into a nested dictionaries\n",
    "\n",
    "# Such as:\n",
    "# A_dict = {\n",
    "#  \"g1\" : {\n",
    "#       \"1\" : adjacency_matrix,\n",
    "#       \"2\" : adjacency_matrix,\n",
    "#           .\n",
    "#           .\n",
    "#           .\n",
    "#   },\n",
    "#   \"g2\" : {\n",
    "#       \"1\" : adjacency_matrix,\n",
    "#       \"2\" : adjacency_matrix,\n",
    "#           .\n",
    "#           .\n",
    "#           .\n",
    "#   },\n",
    "#}\n",
    "\n",
    "# Pickle the dictionary variable\n",
    "with open(\"graphs_adjacency_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(A_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
